{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM Test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3611jvsc74a57bd0f535714c99447282c1e49fee5953987111863f5c57f9ce0267eaed368549fb19",
      "display_name": "Python 3.6.11 64-bit ('reco_base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.11"
    }
  },
  "cells": [
    {
      "source": [
        "This Jupyter notebook will combine the data from survey and data from firestore and use it for training the Machine Learning."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQHara7wukZ9",
        "outputId": "e882565d-5d50-4d12-c12f-3ac62288b027"
      },
      "source": [
        "# set the environment path to find Recommenders\n",
        "import sys\n",
        "sys.path.append(\"../../\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import scrapbook as sb\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from reco_utils.recommender.rbm.rbm import RBM\n",
        "from reco_utils.dataset.python_splitters import numpy_stratified_split\n",
        "from reco_utils.dataset.sparse import AffinityMatrix\n",
        "\n",
        "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "\n",
        "import firebase_admin as fb\n",
        "from firebase_admin import firestore\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Pandas version: {}\".format(pd.__version__))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "This Section will take the data from both firestore and survey"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#initialize firebase-admin library\n",
        "cred = fb.credentials.Certificate('credential.json')\n",
        "fb.initialize_app(cred, {'databaseURL': 'https://keenam-cap0428-default-rtdb.asia-southeast1.firebasedatabase.app'})\n",
        "db = firestore.client()\n",
        "batch = db.batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "#Get data from firestore. data will be taken all documents from a collection\n",
        "ratingVal=5\n",
        "userID_arr=[]\n",
        "movieID_arr=[]\n",
        "rating_arr=[]\n",
        "users_collection='Template_users'\n",
        "\n",
        "actual_user_arr=[]\n",
        "\n",
        "docs = db.collection(users_collection).stream()\n",
        "\n",
        "for doc in docs:\n",
        "    username=doc.id\n",
        "    actual_user_arr.append(username)\n",
        "    for foodname in doc.to_dict()['foodPreference']:\n",
        "        userID_arr.append(username)\n",
        "        movieID_arr.append(foodname)\n",
        "        rating_arr.append(ratingVal)\n",
        "    for foodname in doc.to_dict()['drinkPreference']:\n",
        "        userID_arr.append(username)\n",
        "        movieID_arr.append(foodname)\n",
        "        rating_arr.append(ratingVal)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get data from firestore. data will be taken from all documents with that contain field 'foodPreference' and 'drinkPreference' and from a collection\n",
        "ratingVal=5\n",
        "userID_arr=[]\n",
        "movieID_arr=[]\n",
        "rating_arr=[]\n",
        "\n",
        "actual_user_arr=[]\n",
        "\n",
        "users_collection='users'\n",
        "\n",
        "docs = db.collection(users_collection).stream()\n",
        "\n",
        "for doc in docs:\n",
        "    if 'foodPreference' in doc.to_dict() and 'drinkPreference' in doc.to_dict() and doc.id != '75oB05myWqAonn0HB4cF':\n",
        "        username=doc.id\n",
        "        actual_user_arr.append(username)\n",
        "        for foodname in doc.to_dict()['foodPreference']:\n",
        "            if foodname:\n",
        "                print(username)\n",
        "                print(foodname)\n",
        "                print(ratingVal)\n",
        "                userID_arr.append(username)\n",
        "                movieID_arr.append(foodname)\n",
        "                rating_arr.append(ratingVal)\n",
        "        for foodname in doc.to_dict()['drinkPreference']:\n",
        "            if foodname:\n",
        "                print(username)\n",
        "                print(foodname)\n",
        "                print(ratingVal)\n",
        "                userID_arr.append(username)\n",
        "                movieID_arr.append(foodname)\n",
        "                rating_arr.append(ratingVal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lxsxiE2ivfcC",
        "outputId": "94ff0708-7efd-47c9-a9eb-d6c88e0ca29a"
      },
      "source": [
        "#load survey data from github\n",
        "Retrieval= 'https://raw.githubusercontent.com/b21-cap0428/machine-learning/main/RetrievalV5.csv'\n",
        "data = pd.read_csv(Retrieval)\n",
        "\n",
        "# Convert to 32-bit in order to reduce memory consumption \n",
        "data.loc[:, 'rating'] = data['rating'].astype(np.int32) \n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#generate new userID from both data. \n",
        "#we will also save this array in order to match the userID from firestore and for training the ML\n",
        "last_data_userID=data.tail(1)['userid'].values[0]+1\n",
        "numbered_user_arr=[]\n",
        "for i in range(len(actual_user_arr)):\n",
        "    numbered_user_arr.append(i+last_data_userID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create new combined dataframe for ML\n",
        "new_data=pd.DataFrame([userID_arr,movieID_arr,rating_arr]).T\n",
        "new_data.columns=('userid','foodanddrinkname','rating')\n",
        "#matching the generated userID for firestore and for ML\n",
        "for i in range(len(actual_user_arr)):\n",
        "    new_data['userid'].loc[new_data['userid'] == actual_user_arr[i]]=numbered_user_arr[i]\n",
        "data=pd.concat([data,new_data], ignore_index=True,axis=0)\n",
        "#cast the data into int for training\n",
        "data['userid']=data['userid'].astype('int')\n",
        "data['rating']=data['rating'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#take data column name to prevent hardcoding (only for the training section)\n",
        "userid_colname=data.columns[0]\n",
        "item_colname=data.columns[1]\n",
        "rating_colname=data.columns[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "The machine learning parts below is mostly being kept intact from https://github.com/microsoft/recommenders/blob/main/examples/00_quick_start/rbm_movielens.ipynb.\n",
        "Only reformatted a little bit to prevent hardcoded values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AszWlIyEvmML"
      },
      "source": [
        "#to use standard names across the analysis \n",
        "header = {\n",
        "        \"col_user\": userid_colname,\n",
        "        \"col_item\": item_colname,\n",
        "        \"col_rating\": rating_colname,\n",
        "    }\n",
        "\n",
        "#instantiate the sparse matrix generation  \n",
        "am = AffinityMatrix(DF = data, **header)\n",
        "\n",
        "#obtain the sparse matrix \n",
        "X, _, _ = am.gen_affinity_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7eU9Y0CvvSg"
      },
      "source": [
        "Xtr, Xtst = numpy_stratified_split(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_U5GfZZv0-k"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adRv2SUQv131"
      },
      "source": [
        "#First we initialize the model class\n",
        "model = RBM(hidden_units= 1000, training_epoch = 250, minibatch_size= 60, keep_prob=0.9,with_metrics =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "9Dwz6TyRxspb",
        "outputId": "36f6e2fa-99c6-4ba1-f384-f5264ece3526"
      },
      "source": [
        "#Model Fit\n",
        "train_time= model.fit(Xtr, Xtst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLegLUvCx3Zk"
      },
      "source": [
        "predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zALqjN9yASE"
      },
      "source": [
        "#number of top score elements to be recommended  \n",
        "K = 10\n",
        "\n",
        "#Model prediction on the test set Xtst. \n",
        "top_k, test_time =  model.recommend_k_items(Xtst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F-l3d1Nx6Vk"
      },
      "source": [
        "top_k_df = am.map_back_sparse(top_k, kind = 'prediction')\n",
        "test_df = am.map_back_sparse(Xtst, kind = 'ratings')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n_G5uFYyDVp"
      },
      "source": [
        "top_k_df = am.map_back_sparse(top_k, kind = 'prediction')\n",
        "test_df = am.map_back_sparse(Xtst, kind = 'ratings')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "s7OAR_loyGJ6",
        "outputId": "98d8f390-85ff-45ac-a57b-812538c1e483"
      },
      "source": [
        "top_k_df.sort_values('prediction', ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fenb_AsAyL-x"
      },
      "source": [
        "Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc-Y-T7syNth"
      },
      "source": [
        "def ranking_metrics(\n",
        "    data_size,\n",
        "    data_true,\n",
        "    data_pred,\n",
        "    time_train,\n",
        "    time_test,\n",
        "    K\n",
        "):\n",
        "\n",
        "    eval_map = map_at_k(data_true, data_pred, col_user=userid_colname, col_item=item_colname, \n",
        "                    col_rating=rating_colname, col_prediction=\"prediction\", \n",
        "                    relevancy_method=\"top_k\", k= K)\n",
        "\n",
        "    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user=userid_colname, col_item=item_colname, \n",
        "                    col_rating=rating_colname, col_prediction=\"prediction\", \n",
        "                      relevancy_method=\"top_k\", k= K)\n",
        "\n",
        "    eval_precision = precision_at_k(data_true, data_pred, col_user=userid_colname, col_item=item_colname, \n",
        "                    col_rating=rating_colname, col_prediction=\"prediction\", \n",
        "                               relevancy_method=\"top_k\", k= K)\n",
        "\n",
        "    eval_recall = recall_at_k(data_true, data_pred, col_user=userid_colname, col_item=item_colname, \n",
        "                    col_rating=rating_colname, col_prediction=\"prediction\", \n",
        "                          relevancy_method=\"top_k\", k= K)\n",
        "                          \n",
        "    df_result = pd.DataFrame(\n",
        "        {   \"Dataset\": data_size,\n",
        "            \"K\": K,\n",
        "            \"MAP\": eval_map,\n",
        "            \"nDCG@k\": eval_ndcg,\n",
        "            \"Precision@k\": eval_precision,\n",
        "            \"Recall@k\": eval_recall,\n",
        "            \"Train time (s)\": time_train,\n",
        "            \"Test time (s)\": time_test\n",
        "        }, \n",
        "        index=[0]\n",
        "    )\n",
        "    \n",
        "    return df_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "_uvrLBc1yQUo",
        "outputId": "48b41d62-12c8-408b-c57a-58b4cb1224cb"
      },
      "source": [
        "eval_100k= ranking_metrics(\n",
        "    data_size = \"mv 100k\",\n",
        "    data_true =test_df,\n",
        "    data_pred =top_k_df,\n",
        "    time_train=train_time,\n",
        "    time_test =test_time,\n",
        "    K =10)\n",
        "\n",
        "eval_100k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Send to Firestore"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_k_df.loc[top_k_df[userid_colname] == numbered_user_arr[i]].sort_values('prediction', ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get list of all valid foods and drinks\n",
        "Fooddoc = db.collection('DefaultVal').document('FoodDrink')\n",
        "PossibleFoodandDrink=Fooddoc.get().to_dict()['Food']+Fooddoc.get().to_dict()['Drink']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for i in range(len(actual_user_arr)):\n",
        "    df_to_convert=top_k_df.loc[top_k_df[userid_colname] == numbered_user_arr[i]].sort_values('prediction', ascending = False)\n",
        "    doc_name=actual_user_arr[i]\n",
        "\n",
        "    recommendation_arr=[]\n",
        "    recommendation_dict={}\n",
        "    for j in range(len(df_to_convert)):\n",
        "        #per_recommendation_dict={}\n",
        "        #per_recommendation_dict['food_name']=df_to_convert['movieID'].values[j]\n",
        "        #per_recommendation_dict['rating']=df_to_convert['prediction'].values[j]\n",
        "        #recommendation_arr.append(per_recommendation_dict)\n",
        "        recommendation_dict[df_to_convert[item_colname].values[j]]=df_to_convert['prediction'].values[j]\n",
        "    user_data_dict={'categoryRecommendation': recommendation_dict}\n",
        "    print(users_collection)\n",
        "    print(doc_name)\n",
        "    print(user_data_dict)\n",
        "    user_db = db.collection(users_collection).document(doc_name)\n",
        "    #batch.update(user_db,user_data_dict)\n",
        "    #batch.update(user_db,recommendation_dict)\n",
        "\n",
        "#batch.commit()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(actual_user_arr)):\n",
        "\n",
        "    recommendation_dict={}\n",
        "    doc_name=actual_user_arr[i]\n",
        "    user_db = db.collection(users_collection).document(doc_name)\n",
        "    for key in user_db.get().to_dict().keys():\n",
        "        if key in PossibleFoodandDrink:\n",
        "            recommendation_dict[key]=firestore.DELETE_FIELD\n",
        "\n",
        "    df_to_convert=top_k_df.loc[top_k_df[userid_colname] == numbered_user_arr[i]].sort_values('prediction', ascending = False)\n",
        "\n",
        "    \n",
        "    for j in range(len(df_to_convert)):\n",
        "        #per_recommendation_dict={}\n",
        "        #per_recommendation_dict['food_name']=df_to_convert['movieID'].values[j]\n",
        "        #per_recommendation_dict['rating']=df_to_convert['prediction'].values[j]\n",
        "        #recommendation_arr.append(per_recommendation_dict)\n",
        "        recommendation_dict[df_to_convert[item_colname].values[j]]=df_to_convert['prediction'].values[j]\n",
        "    user_data_dict={'categoryRecommendation': recommendation_dict}\n",
        "    #print(users_collection)\n",
        "    #print(doc_name)\n",
        "    #print(user_data_dict)\n",
        "    #print(user_data_dict)\n",
        "\n",
        "    batch.update(user_db,recommendation_dict)\n",
        "batch.commit()"
      ]
    }
  ]
}